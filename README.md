# DeepHitç”Ÿå­˜åˆ†ææ¨¡å‹ - COPDé¢„åé¢„æµ‹

è¿™æ˜¯ä¸€ä¸ªç”¨äºCOPDï¼ˆæ…¢æ€§é˜»å¡æ€§è‚ºç–¾ç—…ï¼‰é¢„åé¢„æµ‹çš„DeepHitç”Ÿå­˜åˆ†ææ¨¡å‹ã€‚è¯¥æ¨¡å‹åŸºäºæ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œèƒ½å¤Ÿé¢„æµ‹æ‚£è€…çš„ç”Ÿå­˜æ¦‚ç‡å’Œé£é™©è¯„åˆ†ã€‚

## ğŸ“‹ ç›®å½•

- [æ¨¡å‹æ¦‚è¿°](#æ¨¡å‹æ¦‚è¿°)
- [æ¨¡å‹å‚æ•°](#æ¨¡å‹å‚æ•°)
- [å®‰è£…è¯´æ˜](#å®‰è£…è¯´æ˜)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [æ•°æ®æ ¼å¼](#æ•°æ®æ ¼å¼)
- [è¯„ä¼°æŒ‡æ ‡](#è¯„ä¼°æŒ‡æ ‡)
- [æ–‡ä»¶ç»“æ„](#æ–‡ä»¶ç»“æ„)
- [ç¤ºä¾‹ä»£ç ](#ç¤ºä¾‹ä»£ç )
- [å¼•ç”¨](#å¼•ç”¨)

## ğŸ¯ æ¨¡å‹æ¦‚è¿°

DeepHitæ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„ç”Ÿå­˜åˆ†ææ¨¡å‹ï¼Œç”¨äºå¤„ç†å³åˆ å¤±çš„ç”Ÿå­˜æ•°æ®ã€‚æœ¬æ¨¡å‹ä¸“é—¨é’ˆå¯¹COPDæ‚£è€…çš„é¢„åé¢„æµ‹è¿›è¡Œäº†ä¼˜åŒ–ã€‚

### æ¨¡å‹ç‰¹ç‚¹

- **æ·±åº¦å­¦ä¹ æ¶æ„**: ä½¿ç”¨å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ç½‘ç»œ
- **ç¦»æ•£æ—¶é—´å»ºæ¨¡**: å°†è¿ç»­æ—¶é—´ç¦»æ•£åŒ–ä¸ºå¤šä¸ªæ—¶é—´ç‚¹
- **ç«äº‰é£é™©å¤„ç†**: èƒ½å¤Ÿå¤„ç†å¤šç§äº‹ä»¶ç±»å‹
- **é«˜æ€§èƒ½**: åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚

## ğŸ“Š æ¨¡å‹å‚æ•°

æœ€ä½³æ¨¡å‹å‚æ•°ï¼ˆé€šè¿‡è¶…å‚æ•°æœç´¢è·å¾—ï¼‰ï¼š

```json
{
  "alpha": 0.25,
  "batch_size": 32,
  "dropout": 0.4,
  "epochs": 150,
  "hidden_layers": [256],
  "learning_rate": 0.0001,
  "num_durations": 30,
  "sigma": 0.1
}
```

### å‚æ•°è¯´æ˜

- **alpha**: æ’åºæŸå¤±æƒé‡ï¼ˆ0-1ä¹‹é—´ï¼Œå¹³è¡¡ä¼¼ç„¶æŸå¤±å’Œæ’åºæŸå¤±ï¼‰
- **batch_size**: æ‰¹æ¬¡å¤§å°
- **dropout**: Dropoutæ¯”ç‡ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
- **epochs**: è®­ç»ƒè½®æ•°
- **hidden_layers**: éšè—å±‚ç»“æ„ï¼ˆ[256]è¡¨ç¤ºå•å±‚256ä¸ªç¥ç»å…ƒï¼‰
- **learning_rate**: å­¦ä¹ ç‡
- **num_durations**: ç¦»æ•£æ—¶é—´ç‚¹æ•°é‡
- **sigma**: æ’åºæŸå¤±å¹³æ»‘å‚æ•°

## ğŸ”§ å®‰è£…è¯´æ˜

### 1. ç¯å¢ƒè¦æ±‚

- Python >= 3.7
- PyTorch >= 1.9.0

### 2. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 3. éªŒè¯å®‰è£…

```python
import torch
import pycox
import torchtuples
print("å®‰è£…æˆåŠŸï¼")
```

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿå¼€å§‹

1. **å‡†å¤‡æ•°æ®**

   ç¡®ä¿æ‚¨çš„æ•°æ®æ ¼å¼ç¬¦åˆè¦æ±‚ï¼ˆè§[æ•°æ®æ ¼å¼](#æ•°æ®æ ¼å¼)éƒ¨åˆ†ï¼‰

2. **åŠ è½½æ¨¡å‹**

```python
from utils.model_loader import DeepHitModelLoader

# åˆå§‹åŒ–åŠ è½½å™¨
loader = DeepHitModelLoader(
    model_path="models/deephit_model.pkl",
    config_path="models/model_config.json"
)

# åŠ è½½æ¨¡å‹å’Œé…ç½®
loader.load_config()
loader.load_model()
```

3. **æ‹Ÿåˆæ ‡å‡†åŒ–å™¨**

```python
import pandas as pd

# åŠ è½½è®­ç»ƒæ•°æ®ï¼ˆç”¨äºæ‹Ÿåˆæ ‡å‡†åŒ–å™¨ï¼‰
train_data = pd.read_csv("data/train_data.csv")
X_train = train_data.drop(['ID', 'Time', 'Event'], axis=1)

# æ‹Ÿåˆæ ‡å‡†åŒ–å™¨
loader.fit_scaler(X_train)
```

4. **è¿›è¡Œé¢„æµ‹**

```python
# åŠ è½½æµ‹è¯•æ•°æ®
test_data = pd.read_csv("data/test_data.csv")
X_test = test_data.drop(['ID', 'Time', 'Event'], axis=1)

# é¢„æµ‹ç”Ÿå­˜æ¦‚ç‡
survival_probs = loader.predict_survival(X_test, return_df=True)

# é¢„æµ‹é£é™©è¯„åˆ†
risk_scores = loader.predict_risk_score(X_test)
```

5. **è¯„ä¼°æ¨¡å‹**

```python
from utils.evaluator import ModelEvaluator

evaluator = ModelEvaluator()

# è®¡ç®—C-index
c_index = evaluator.calculate_c_index(
    risk_scores, 
    test_data['Time'], 
    test_data['Event']
)

print(f"C-index: {c_index:.4f}")
```

### å®Œæ•´ç¤ºä¾‹

å‚è§ `examples/validate_model.py` æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«å®Œæ•´çš„éªŒè¯æµç¨‹ã€‚

## ğŸ“ æ•°æ®æ ¼å¼

### è¾“å…¥æ•°æ®è¦æ±‚

æ•°æ®åº”ä¸ºCSVæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹åˆ—ï¼š

- **ID**: æ‚£è€…IDï¼ˆå¯é€‰ï¼‰
- **Time**: ç”Ÿå­˜æ—¶é—´ï¼ˆæœˆï¼‰
- **Event**: äº‹ä»¶çŠ¶æ€ï¼ˆ1=å‘ç”Ÿäº‹ä»¶ï¼Œ0=åˆ å¤±ï¼‰
- **ç‰¹å¾åˆ—**: å…¶ä½™åˆ—ä¸ºæ¨¡å‹è¾“å…¥ç‰¹å¾

### ç¤ºä¾‹æ•°æ®æ ¼å¼

```csv
ID,Time,Event,Feature1,Feature2,Feature3,...
1,24.5,1,0.5,1.2,3.4,...
2,36.0,0,0.8,1.5,2.9,...
3,18.2,1,0.3,0.9,4.1,...
```

### ç‰¹å¾è¦æ±‚

- ç‰¹å¾åº”ä¸ºæ•°å€¼å‹
- ç¼ºå¤±å€¼åº”åœ¨ä½¿ç”¨å‰å¤„ç†ï¼ˆå»ºè®®ä½¿ç”¨ä¸­ä½æ•°å¡«å……ï¼‰
- ç‰¹å¾é¡ºåºåº”ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´

## ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡

æ¨¡å‹æä¾›ä»¥ä¸‹è¯„ä¼°æŒ‡æ ‡ï¼š

### 1. C-indexï¼ˆä¸€è‡´æ€§æŒ‡æ•°ï¼‰

è¡¡é‡æ¨¡å‹é¢„æµ‹é£é™©æ’åºçš„å‡†ç¡®æ€§ï¼ŒèŒƒå›´0-1ï¼Œè¶Šé«˜è¶Šå¥½ã€‚

```python
c_index = evaluator.calculate_c_index(risk_scores, time_data, event_data)
```

### 2. ROC AUC

ç‰¹å®šæ—¶é—´ç‚¹çš„ROCæ›²çº¿ä¸‹é¢ç§¯ï¼Œç”¨äºè¯„ä¼°äºŒåˆ†ç±»æ€§èƒ½ã€‚

```python
roc_auc = evaluator.calculate_roc_auc_at_time(
    survival_prob, time_data, event_data, time_point=36
)
```

### 3. Integrated Brier Score (IBS)

ç»¼åˆBrierè¯„åˆ†ï¼Œè¡¡é‡é¢„æµ‹æ ¡å‡†åº¦ï¼Œè¶Šä½è¶Šå¥½ã€‚

```python
ibs = evaluator.calculate_ibs(survival_probs_df, time_data, event_data)
```

### 4. Kaplan-Meier Log-rank På€¼

ç”¨äºè¯„ä¼°é£é™©åˆ†ç»„çš„æ˜¾è‘—æ€§ã€‚

```python
p_value = evaluator.calculate_km_pvalue(
    risk_scores, time_data, event_data, n_groups=3
)
```

## ğŸ“‚ æ–‡ä»¶ç»“æ„

```
DeepHit_Model_GitHub/
â”œâ”€â”€ README.md                 # æœ¬æ–‡ä»¶
â”œâ”€â”€ requirements.txt          # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ models/                   # æ¨¡å‹æ–‡ä»¶ç›®å½•
â”‚   â””â”€â”€ model_config.json    # æ¨¡å‹é…ç½®æ–‡ä»¶
â”œâ”€â”€ data/                     # æ•°æ®ç›®å½•ï¼ˆç”¨æˆ·æä¾›ï¼‰
â”‚   â”œâ”€â”€ train_data.csv       # è®­ç»ƒæ•°æ®
â”‚   â””â”€â”€ test_data.csv        # æµ‹è¯•æ•°æ®
â”œâ”€â”€ utils/                    # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ model_loader.py      # æ¨¡å‹åŠ è½½å™¨
â”‚   â””â”€â”€ evaluator.py         # è¯„ä¼°å·¥å…·
â””â”€â”€ examples/                 # ç¤ºä¾‹ä»£ç 
    â””â”€â”€ validate_model.py     # éªŒè¯ç¤ºä¾‹
```

## ğŸ’¡ ç¤ºä¾‹ä»£ç 

### åŸºæœ¬ä½¿ç”¨

```python
from utils.model_loader import DeepHitModelLoader
from utils.evaluator import ModelEvaluator
import pandas as pd

# 1. åŠ è½½æ¨¡å‹
loader = DeepHitModelLoader(
    model_path="models/deephit_model.pkl",
    config_path="models/model_config.json"
)
loader.load_config()
loader.load_model()

# 2. å‡†å¤‡æ•°æ®
train_data = pd.read_csv("data/train_data.csv")
test_data = pd.read_csv("data/test_data.csv")

X_train = train_data.drop(['ID', 'Time', 'Event'], axis=1)
X_test = test_data.drop(['ID', 'Time', 'Event'], axis=1)

# 3. æ‹Ÿåˆæ ‡å‡†åŒ–å™¨
loader.fit_scaler(X_train)

# 4. é¢„æµ‹
survival_probs = loader.predict_survival(X_test)
risk_scores = loader.predict_risk_score(X_test)

# 5. è¯„ä¼°
evaluator = ModelEvaluator()
c_index = evaluator.calculate_c_index(
    risk_scores, 
    test_data['Time'], 
    test_data['Event']
)

print(f"C-index: {c_index:.4f}")
```

### æ‰¹é‡é¢„æµ‹

```python
# å¯¹å¤šä¸ªæ ·æœ¬è¿›è¡Œé¢„æµ‹
results = []
for idx, row in test_data.iterrows():
    X_sample = row.drop(['ID', 'Time', 'Event']).values.reshape(1, -1)
    X_sample_df = pd.DataFrame(X_sample, columns=X_train.columns)
    
    surv_prob = loader.predict_survival(X_sample_df)
    risk_score = loader.predict_risk_score(X_sample_df)
    
    results.append({
        'ID': row['ID'],
        'Risk_Score': risk_score[0],
        'Survival_Prob_36m': surv_prob.loc[36, 0] if 36 in surv_prob.index else None
    })

results_df = pd.DataFrame(results)
results_df.to_csv('predictions.csv', index=False)
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®æ ‡å‡†åŒ–**: å¿…é¡»ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ ‡å‡†åŒ–æ–¹æ³•ï¼Œå»ºè®®ä½¿ç”¨æä¾›çš„`fit_scaler`æ–¹æ³•
2. **ç‰¹å¾é¡ºåº**: ç¡®ä¿ç‰¹å¾åˆ—çš„é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´
3. **ç¼ºå¤±å€¼**: åœ¨ä½¿ç”¨å‰å¤„ç†æ‰€æœ‰ç¼ºå¤±å€¼
4. **æ—¶é—´å•ä½**: ç¡®ä¿æ—¶é—´å•ä½ä¸ºæœˆï¼Œä¸è®­ç»ƒæ•°æ®ä¸€è‡´
5. **æ¨¡å‹æ–‡ä»¶**: éœ€è¦æä¾›è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶ï¼ˆ.pklæ ¼å¼ï¼‰

## ğŸ”¬ æ¨¡å‹æ€§èƒ½

åœ¨åŸå§‹æ•°æ®é›†ä¸Šçš„æ€§èƒ½è¡¨ç°ï¼š

- **C-index**: 0.72-0.78
- **ROC AUC (36æœˆ)**: 0.68-0.75
- **ROC AUC (48æœˆ)**: 0.70-0.78
- **ROC AUC (60æœˆ)**: 0.65-0.72

*æ³¨ï¼šå®é™…æ€§èƒ½å¯èƒ½å› æ•°æ®é›†è€Œå¼‚*

## ğŸ“ å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨æœ¬æ¨¡å‹ï¼Œè¯·å¼•ç”¨ç›¸å…³è®ºæ–‡ï¼š

```bibtex
@article{deephit2018,
  title={DeepHit: A Deep Learning Approach to Survival Analysis with Competing Risks},
  author={Lee, Changhee and Zame, William and Yoon, Jinsung and van der Schaar, Mihaela},
  journal={AAAI},
  year={2018}
}
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ã€‚

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡GitHub Issuesè”ç³»ã€‚

---

**æ³¨æ„**: æœ¬æ¨¡å‹ä»…ç”¨äºç ”ç©¶ç›®çš„ï¼Œä¸åº”ç”¨äºä¸´åºŠè¯Šæ–­æˆ–æ²»ç–—å†³ç­–ã€‚

